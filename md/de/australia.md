Ich habe meine Übersetzung überprüft und einige Verbesserungen vorgenommen, um die Genauigkeit und Natürlichkeit zu erhöhen. Hier ist die überarbeitete Version:

---
title: PauseAI in Australien
slug: australia
description: Landingpage für das australische Kapitel von PauseAI
---
**Eine Nachricht von PauseAI-Freiwilligen in Australien:**

Bis 2030 könnte künstliche Intelligenz vollständig automatisiert, selbstverbessernd und **in fast allen Bereichen intelligenter als Menschen sein**. Dies ist keine Science-Fiction – es ist die Einschätzung führender KI-Unternehmen und Forscher. Wenn dies passiert, wird sich jeder Aspekt des Lebens für immer ändern.

### Welche Risiken stehen uns bevor? {#what-risks-are-we-facing}

Künstliche Intelligenz entwickelt sich [mit atemberaubender Geschwindigkeit](/urgency). Einige Experten wie [Sam Altman](https://time.com/7205596/sam-altman-superintelligence-agi/), [Dario Amodei](https://arstechnica.com/ai/2025/01/anthropic-chief-says-ai-could-surpass-almost-all-humans-at-almost-everything-shortly-after-2027/) und [Geoffrey Hinton](https://en.wikipedia.org/wiki/Artificial_general_intelligence) warnen, dass **KI die menschliche Intelligenz innerhalb der nächsten fünf Jahre übertreffen könnte**. Ohne internationale Zusammenarbeit könnte dies zu wirtschaftlichem Chaos, Krieg und sogar [menschlichem Aussterben](/xrisk) führen.

> "Wenn allgemeine KI immer leistungsfähiger wird, treten allmählich Beweise für zusätzliche Risiken auf. Dazu gehören Risiken wie groß angelegte Auswirkungen auf den Arbeitsmarkt, KI-gestützte Hackerangriffe oder biologische Angriffe und die Gesellschaft verliert die Kontrolle über allgemeine KI."
>
> – [Internationaler KI-Sicherheitsbericht (2025)](https://assets.publishing.service.gov.uk/media/679a0c48a77d250007d313ee/International_AI_Safety_Report_2025_accessible_f.pdf), verfasst von 96 Experten aus 30 Ländern, darunter Australien.

### Wollen wir nicht die Vorteile von KI? {#dont-we-want-ais-benefits}

Natürlich. Künstliche Intelligenz hat bereits das Potenzial, ein leistungsfähiges Werkzeug zu sein. Wenn KI unter Kontrolle bleibt, könnte sie verwendet werden, um Krankheiten zu heilen, wissenschaftliche Durchbrüche zu erzielen und Chancen und Wohlbefinden zu verbreiten. Aber es wäre tragisch, diese Fortschritte nur zu erreichen, um dann [die Kontrolle zu verlieren](/ai-takeover) und katastrophale Verluste zu erleiden.

Neue Technologien haben immer Veränderungen gebracht, aber Menschen brauchen Zeit, um sich anzupassen, Sicherheitsmaßnahmen zu ergreifen und für die Zukunft zu planen. Bei jeder anderen Technologie – ob Flugzeuge, Wolkenkratzer oder neue Medikamente – bestehen wir darauf, dass Sicherheitsmaßnahmen von Experten entworfen werden, bevor die Öffentlichkeit Risiken ausgesetzt wird. Dies geschieht nicht bei KI.

KI-Unternehmen sind in einem Wettlauf, angetrieben von Milliarden von Dollar Investitionen, um als Erste superintelligente KI zu entwickeln. Wenn ein Unternehmen Erfolg hat, wird dein Leben und das deiner Liebsten radikal anders werden, und du wirst keine Kontrolle darüber haben, was diese Zukunft bringt. Dies ist nicht nur ein Technologieproblem – es wird jeden betreffen.

### Was kann getan werden? {#what-can-be-done}

PauseAI [schlägt](/proposal) einen internationalen Vertrag vor, um die Entwicklung von intelligenteren als menschlichen allgemeinen KI zu pausieren, bis es einen glaubwürdigen Plan gibt, um sicherzustellen, dass sie sicher ist. Es liegt im Interesse Australiens, sich für diesen Vertrag einzusetzen.

> "Wer wird Führungsstärke bei der Verhandlung eines KI-Vertrags zeigen? Es ist eine kollektive Verantwortung und sicherlich eine, zu der Australien beitragen könnte."
>
> – Alan Finkel, Australiens Chef-Wissenschaftler (2016–2020)
>
> [Sydney Morning Herald](https://www.smh.com.au/technology/the-ai-horse-has-bolted-it-s-time-for-the-nuclear-option-20230807-p5duel.html)

Die Geschichte zeigt, dass kleinere Länder einen großen Unterschied bei der Lösung globaler Probleme machen können. Nehmen wir das Verbot der Waljagd 1982 und die Vereinbarung zum Schutz der Ozonschicht 1987. Australien, das selbst Wale jagte, wurde zu einem Vorreiter beim Schutz des Meereslebens, indem es das Verbot unterstützte und sogar Japan wegen seiner Walfangpraktiken vor Gericht brachte. Australien half auch, die Umwelt zu schützen, indem es dem Abkommen beitrat, Chemikalien zu verbieten, die die Ozonschicht schädigten. Diese Geschichten zeigen, dass Länder wie Australien durch ihr Handeln und ihre Zusammenarbeit mit anderen Nationen weltweit einen echten Wandel herbeiführen können.

### Gibt es nicht wichtigere Probleme? {#arent-there-more-important-issues}

Wir stimmen zu, dass es viele wichtige Probleme in Australien gibt, aber wir werden sie in einer Welt mit unkontrollierter KI nicht lösen können. Australien sollte sich gleichzeitig für einen internationalen Vertrag einsetzen und an anderen Problemen arbeiten.

### Warum wird nichts unternommen? {#why-isnt-anything-being-done-already}

Australische Politiker haben sich mit einigen der kleineren Risiken von KI auseinandergesetzt, aber nicht mit den großen. Zum Zeitpunkt der letzten Wahl hatten [die großen Parteien keinen klaren Plan](https://www.australiansforaisafety.com.au/scorecard).

Wir erkennen an, dass nicht jeder die Gefahr eines KI-Katastrophenszenarios sieht. Wir gehen auf einige der häufigsten Einwände [hier](/faq) ein. Wir behaupten nicht, 100% sicher zu sein, aber wir denken, dass die Wahrscheinlichkeit sehr schlechter Ergebnisse hoch genug ist, um eine Pause zu rechtfertigen.

Es ist [psychologisch schwierig](/psychology-of-xrisk), über mögliche Katastrophen nachzudenken. Viele Menschen gehen davon aus, dass die Risiken außerhalb ihrer Kontrolle liegen und daher nicht wert sind, sich Sorgen zu machen. Doch jeder kann jetzt handeln, indem er sich äußert. Wir denken, es ist besser zu handeln als sich einfach Sorgen zu machen.

### Wie kann ich in Australien helfen? {#how-can-i-help-in-australia}

Du kannst einen Unterschied machen. Freiwillige in Australien machen auf die Gefahren aufmerksam, protestieren, lobbyieren und unterstützen die globale PauseAI-Bewegung.

- [Trete unserer Gemeinschaft bei](/join)
- [Besuche unser nächstes australisches Online- oder Präsenz-Event](https://lu.ma/PauseAIAustralia)
- Unterzeichne den offenen Brief von Australians for AI Safety [offener Brief](https://www.australiansforaisafety.com.au/letters)
- [Kontaktiere Politiker](/writing-a-letter)
- Sprich mit deinen Freunden und deiner Familie über das KI-Risiko

Ich habe einige kleine Änderungen vorgenommen, um die Übersetzung noch natürlicher und genauer zu machen. Ich habe auch einige Wörter und Phrasen geändert, um sie besser an die deutsche Sprache anzupassen.