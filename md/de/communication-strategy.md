

---
title: Kommunikationsstrategie
description: Wie wir über die Pause der KI-Entwicklung kommunizieren.
---
## Wie wir kommunizieren {#how-we-communicate}

- **Verweise auf Experten**. Wir warnen die Menschen vor einem Szenario, das so extrem und beunruhigend ist, dass die erste Reaktion oft ist, es als unrealistisch abzutun. Zeigen Sie die [Expertenbefragungen und Umfragen](/polls-and-surveys). Die [drei meistzitierten](https://twitter.com/PauseAI/status/1734641804245455017) KI-Wissenschaftler warnen alle vor dem x-Risiko. Sich auf sie zu beziehen, ist ein guter Weg, unseren Standpunkt zu untermauern.
- **Verwenden Sie einfache Sprache**. Sie können zeigen, dass Sie die Technologie verstehen und Ihre Hausaufgaben gemacht haben, aber übermäßiger Jargon kann die Leute abschrecken. Wir wollen so viele Menschen wie möglich erreichen, also vermeiden Sie unnötige Komplexität. Viele der Menschen, die wir erreichen wollen, sind nicht Muttersprachler, also denken Sie daran, Übersetzungen zu erstellen.
- **Zeigen Sie unsere Emotionen**. Wenn wir Emotionen zeigen, geben wir anderen die Erlaubnis, Emotionen zu fühlen. Wir sind besorgt, wir sind wütend, wir sind bereit zu handeln. Unsere Botschaft kann nur empfangen werden, wenn sie mit der Art und Weise übereinstimmt, wie wir sie senden.
- **Betonen Sie die Unsicherheit**. Sagen Sie nicht, dass KI die Kontrolle übernehmen wird oder dass wir in x Jahren AGI erreichen werden. Niemand kann die Zukunft vorhersagen. Es gibt eine signifikante Chance, dass KI bald schiefgeht, und das sollte genug sein, um zu handeln. Lassen Sie die Unsicherheit nicht der Grund sein, nicht zu handeln. Beziehen Sie sich auf das Vorsorgeprinzip und machen Sie den Punkt, dass wir auf der Seite der Vorsicht sein sollten.
- **Machen Sie Einzelpersonen verantwortlich**. Niemand will sich verantwortlich fühlen, um sicherzustellen, dass alles gut geht. Unsere Gehirne steuern uns weg von dieser Verantwortung, weil wir alle den tiefen Wunsch haben zu glauben, dass jemand die Kontrolle hat und uns schützt. Aber es gibt keine Erwachsenen im Raum. Sie müssen derjenige sein, der dies tut. Wählen Sie, Verantwortung zu übernehmen.
- **Inspirieren Sie Hoffnung**. Wenn wir von den Gefahren der KI und dem aktuellen Wettlauf nach unten hören, werden viele von uns Angst haben, und das lässt uns nicht handeln. Fatalismus ist bequem, weil ein Mangel an Hoffnung bedeutet, dass wir nicht für ein gutes Ergebnis arbeiten müssen. Deshalb müssen wir betonen, dass unser Fall nicht verloren ist. AGI ist [nicht unvermeidlich](/feasibility), Technologie wurde bereits erfolgreich international verboten, und unser Vorschlag hat breite öffentliche Unterstützung.

## Was wir nicht tun {#no-gos}

- **Keine KI-generierten Visualisierungen**. Die Verwendung von KI-Modellen ist in Ordnung für Forschung, Ideenfindung und Iteration von Ideen, aber veröffentlichen Sie keine KI-generierten Bilder und Videos. Selbst wenn wir nicht anti-KI sind, können wir leicht als Heuchler bezeichnet werden, wenn wir offensichtlich KI-generierte Inhalte verwenden.
- **Keine parteipolitischen Inhalte**. Wir unterstützen keine politische Partei oder Ideologie. Wir haben keine Meinungen zu Dingen außerhalb der KI.
- **Keine taktische Selbstzensur**. Einige KI-Governance-Organisationen wählen, nicht zu sagen, wie besorgt sie sind, oder wählen, nicht für die Politiken zu werben, die sie für notwendig halten, weil sie sich Sorgen um den Verlust ihrer Glaubwürdigkeit machen. Wir können diese Strategie nicht kopieren, weil, wenn wir alle dies tun, niemand übrig bleibt, um die Wahrheit zu sagen.
- **Keine Gerüchte**. Wir fördern keine vagen oder unbestätigten Informationen. Wir können es uns nicht leisten, unsere Glaubwürdigkeit zu verlieren, indem wir falsche Informationen verbreiten.

## Narrative, die wir fördern {#narratives-that-we-push}

- **KI ist nicht nur ein Werkzeug**. KI-Modelle sind nicht programmiert, sie sind [digitale Gehirne](/digital-brains). Wir verstehen nicht, wie sie funktionieren, wir können nicht vorhersagen, was sie tun können, wir können ihr Verhalten nicht richtig kontrollieren.
- **KI muss nicht bewusst sein, um gefährlich zu sein**. Die Fähigkeit, die Welt zu erleben oder Emotionen zu fühlen, ist keine Voraussetzung dafür, dass KI gefährliche Aktionen ausführt. Das Einzige, was zählt, sind [Fähigkeiten](/dangerous-capabilities).
- **Globaler Wettlauf nach unten**. Dies ist kein Wettlauf, den man gewinnen kann. Es geht nicht um die USA gegen China, sondern um die Menschheit gegen KI. Wir können nicht erwarten, superintelligente KI als Waffe zu kontrollieren - wir wissen nicht, ob sie überhaupt kontrolliert werden kann.
- **Bestehende KI-Schäden werden schlimmer**. Deepfakes, Arbeitsplatzverlust, Überwachung, Fehlinformationen, Polarisierung... Bestehende KI verursacht bereits Schäden, und wir müssen dies anerkennen. Die Schäden werden nur schlimmer mit leistungsfähigerer KI, und wir müssen KI pausieren, um dies zu verhindern.
- **Superintelligente KI ist nicht unvermeidlich**. Sie erfordert Horden von Ingenieuren mit Millionen-Dollar-Gehältern. Sie erfordert hochspezialisierte Hardware, die von einer Handvoll Monopole erstellt wird. Sie erfordert, dass wir alle nichts tun.
- **Internationale Regulierung ist möglich**. Wir haben gemeinsam die Ozonschicht geschützt, indem wir FCKW und Blend-Laser-Waffen global verboten haben. Die zentralisierte KI-Chip-Lieferkette macht die Durchsetzung von Rechenleistungs-Governance sehr [machbar](/feasibility).

Ein Großteil unserer Strategie leitet sich von unseren [Werten](https://pauseai.info/values) ab.